# Assignment 1: Comparison of the Performance of Different Supervised Models

**Due Date**: December 2, 2024, 23:59  

### Overview

This assignment evaluates our understanding of applying and comparing the performances of various supervised machine learning algorithms. For this task, you will use the **FIFA 18 players database** to develop and analyze machine learning models, focusing on **Naive Bayes Classifiers**, **Random Forest**, and **Support Vector Machines**.

---

### Data Description

The FIFA 18 player dataset includes information on over **17,000 players**, each with **70+ attributes**. These attributes span:
- **Player statistics**: Dribbling, Aggression, Goalkeeper Skills, etc.
- **Personal data**: Nationality, Club, Age, Wage, Salary, and more.

This dataset provides a rich set of features for analyzing and predicting player attributes and capabilities.

To download the dataset, click [here](https://canvas.mdu.se/courses/15513/files/2167729?wrap=1).

Additionally, we may explore other models such as **Decision Tree** and **k-Nearest Neighbors (k-NN)**, although this is optional.

---

### Your Task

1. **Define the Problem**  
   Specify what problem we are aiming to solve using this dataset (e.g., predicting player value, skill-based role classification, etc.).

2. **Develop Models**  
   Build machine learning models using the following algorithms:
   - **Naive Bayes Classifier**
   - **Random Forest**
   - **Support Vector Machine (SVM)**

3. **Evaluate Model Performance**  
   Compare the performance of each model.

4. **Submit Code and Report**  
   Provide both our code and a report detailing your findings.

---

### Report Instructions

The report should be a maximum of **4 pages** and include the following sections:

- **Problem Formulation**  
  Briefly describe the problem we are solving and its relevance.

- **Data Sampling**  
  Outline how we sampled the data for training and testing.

- **Hyperparameter Values**  
  List the chosen hyperparameters for each algorithm, along with our rationale.

- **Model Selection Method**  
  Describe the model selection method (e.g., cross-validation or hold-out) and explain why it was chosen.

- **Evaluation Metrics**  
  Specify the evaluation metrics used to compare models and justify your choices.

- **Summary of Results**  
  Present results using tables and graphs to highlight key findings.

- **Performance Discussion**  
  Discuss the performance of the algorithms, including any limitations, the effect of chosen hyperparameters, etc.

**File Naming Convention**: Save both the code and report as `DVA263_INL1_Group_Id`.

---
