\section{Feature transformation process}


\subsection{Artificial neural network}

Feature transformation process for an ANN involves transforming the input data through the network layers to produce the prediction.

\subsubsection{Transformation Through Network Layers}
The data is preprocessed and features are extracted as mention in the subsection Data Preparation and Feature Extraction, it is now ready to be fed into the ANN. The transformation process through the network layers includes these steps:
\begin{itemize}
    \item \textbf{Input Layer}: The input data is fed into the input layer.
    \item \textbf{Hidden Layers}: The input data is then passed through the hidden layers. Each hidden layer consists of neurons that apply a linear transformation followed by a non-linear activation function, we use the function ReLu. The weights and biases of the neurons are learned during the training process.
    \item \textbf{Dropout and Regularization}: To prevent overfitting, dropout layers is added after some hidden layers. Dropout randomly drops some inputs during training to prevent overfitting, and L2 regularization helps by limiting large weights.
    \item \textbf{Output Layer}: The final layer contains neurons equal to the number of possible classes, which is 10 in our case. A softmax activation function is then applied, to output the probability for each class.
\end{itemize}
From the output layer, the predicted label is the class with the highest probability.

\subsection{Convolutional neural network}

