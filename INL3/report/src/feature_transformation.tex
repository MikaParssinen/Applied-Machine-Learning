\section{Feature transformation process}

\subsection{Artificial neural network}

Feature transformation in an ANN involves processing input data through the network layers to generate predictions.
After preprocessing and feature extraction, as described in the subsection Data Preparation and Feature Extraction, the data is ready for input into the ANN. 
The transformation process through the network layers includes the following steps:
\begin{itemize}
    \item \textbf{Input Layer}: The input data is fed into the input layer.
    \item \textbf{Hidden Layers}: The input data is then passed through the hidden layers. Each hidden layer consists of neurons that apply a linear transformation followed by a non-linear activation function, we use the function ReLu. The weights and biases of the neurons are learned during the training process.
    \item \textbf{Dropout and Regularization}: To prevent overfitting, dropout layers is added after some hidden layers. Dropout randomly drops some inputs during training to prevent overfitting, and L2 regularization helps by limiting large weights.
    \item \textbf{Output Layer}: The final layer contains neurons equal to the number of possible classes, which is 10 in our case. A softmax activation function is then applied, to output the probability for each class.
\end{itemize}
From the output layer, the predicted label is the class with the highest probability.

\subsection{Convolutional neural network}

The feature transformation process in a convolutional neural network (CNN) involves passing the input data through convolutional layers, pooling layers and fully connected layers to extract features of a given image that defines a specific class. These are the steps:

\begin{itemize}
    \item \textbf{Input Layer}: The input data with right shape is fed into the input layer.
    \item \textbf{Convolution Layer}: The feature transformation process that defines a convolutional neural network (CNN) is in the convolution layer. By using one or more filters, and processing an image with a convolution operation, the CNN can learn to detect features in the image. A filter is a $m \times n$ matrix that moves over the input and computes the dot product between the filter and the input it covers at each position. A filter can extract features such as edges and textures. 
    \par
    The filters are learned during the training process, and each filter of the CNN can learn to detect unique features that are useful for the classification task. Before passing on the output of the convolution layer to the next layer, the output is passed through an activation function, such as the rectified linear unit (ReLU) function. The ReLU function is used to introduce non-linearity to the model, which allows the CNN to learn complex patterns in the data.
    \item \textbf{Pooling Layer}: The output of the convolution layer is then passed through a pooling layer. The pooling layer reduces the spatial dimension of each feature map without loosing essential information. A common method is called max pooling which extracts the maximum value from subsections of the feature map.
    \item \textbf{Fully Connected Layer}: After the input goes through various convolutional and pooling layers, the output is flattened into a vector and passed through one or more fully connected layers. The fully connected layers are used to reason about the features extracted by the previous layers to identify patterns. In the case of identifying handwritten digits, the fully connected layers take a look at the features of the input image and determine which features are important to classify a digit.
    \item \textbf{Output Layer}: The final layer of the CNN is the output layer, which uses a softmax activation function to output the probability of each class. 
\end{itemize}

