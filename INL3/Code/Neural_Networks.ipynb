{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c137da0",
   "metadata": {},
   "source": [
    "# DVA263 - Applied Machine Learning\n",
    "\n",
    "### Exercise\n",
    "\n",
    "This exercise involves the development of an Artificial Neural Network (ANN) that classifies handwritten digits from the MNIST dataset. The task will require preprocessing the data, constructing the network, and then training the model to recognize digit images.\n",
    "\n",
    "<span style=\"color:red\">Note:</span>\n",
    "Please make sure that the system have following packages installed before doing the exercise.\n",
    "* Numpy\n",
    "* OpenCV\n",
    "* Tensorflow\n",
    "* Scipy\n",
    "* Scikit-learn\n",
    "* Matplotlib\n",
    "* Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb9054",
   "metadata": {},
   "source": [
    "# *Libraries*\n",
    "\n",
    "Libraries have already been declared. Please declare any additional libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27fb1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from scipy.ndimage import sobel\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0a4ca",
   "metadata": {},
   "source": [
    "# *Load the MNIST Dataset*\n",
    "\n",
    "The MNIST dataset consists of 60,000 images for training and 10,000 images for testing, all of which contain handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd951af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to load the MNIST hand written digit dataset\n",
    "# You do not need to change anything here\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b179abe",
   "metadata": {},
   "source": [
    "# *Plot First Ten Images*\n",
    "\n",
    "Plotting images will help to understand the how each image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9194f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You do not need to change anything here.\n",
    "\n",
    "def plot_first_ten_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e860b",
   "metadata": {},
   "source": [
    "# *Sobel Operator Edge Feature Extraction*\n",
    "\n",
    "Edge detection from images is achieved through the utilization of the Sobel operator algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce823126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes images as input and extract edge features\n",
    "# You do not need to change anything here.\n",
    "\n",
    "def extract_edge_features(images):\n",
    "    sobel_images = np.array([sobel(image, axis=-1) for image in images])\n",
    "    return sobel_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b00f2",
   "metadata": {},
   "source": [
    "# *Data Preparation for Artificial Neural Networks*\n",
    "\n",
    "Prepare the dataset for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3dd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(): # Insert parameters name \n",
    "    \n",
    "    # Please perform follwoing tasks to prepare final data\n",
    "    \n",
    "    \"\"\" ------ Task 1 - Feature Extraction.----------\n",
    "    # Instruction:\n",
    "    #    - Call the \"extract_edge_features()\" function with \"x_train\" and \"x_test\" to extract edge features from the images.\n",
    "    #    - Store the resulting edge features in \"x_train_edges\" and \"x_test_edges\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"--------- Task 2 - Normalization. ------------\n",
    "    # Instruction:\n",
    "    #    - Normalize these edge features by scaling the pixel values to a range of [0, 1].\n",
    "    #    - This is done by dividing by the maximum value of a pixel, which is 255.\n",
    "    #    - Store the normalized data again in \"x_train_edges\" and \"x_test_edges\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"----------- Task 3 - Flattening.----------\n",
    "    # Instruction:\n",
    "    #    - Flatten the normalized edge feature images to create a one-dimensional array for each image.\n",
    "    #    - This is necessary because the neural network expects a flat array of inputs.\n",
    "    #    - Store the flattened data in \"x_train_flat\" and \"x_test_flat\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"--------- Task 4 - One-Hot Encoding.-------------\n",
    "    # Instruction:\n",
    "    #    - Convert the categorical integer labels into a binary matrix representation using one-hot encoding.\n",
    "    #    - This step is crucial for classification tasks to properly format the labels for the output layer of the network.\n",
    "    #    - Store the one-hot encoding data in \"y_train_encoded\" and \"y_test_encoded\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\"------------- Task 5 - After these preprocessing steps, the function will return four variables.-------\n",
    "    # - \"x_train_flat\": the flattened training features\n",
    "    # - \"y_train_encoded\": the one-hot encoded training labels\n",
    "    # - \"x_test_flat\": the flattened testing features\n",
    "    # - \"y_test_encoded\": the one-hot encoded testing labels\n",
    "    \"\"\"    \n",
    "    return  # Insert the name of four variables as instruction to return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c170f",
   "metadata": {},
   "source": [
    "# *Build ANN Model*\n",
    "\n",
    "Build the ANN model using hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6826cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Neural Network Architecture inside the \"build_model()\" function.\n",
    "\n",
    "\"\"\"----- Instructions --------\n",
    "    - Use the Sequential model from Keras to stack layers in a linear format.\n",
    "    - Start with a dense layer where input shape corresponding to the image data dimensions.\n",
    "    - Use necessary activation fuction in each dense layer.\n",
    "    - Continue adding dense layers reducing the number of neurons in each subsequent layer.\n",
    "    - Apply L2 regularization if necessary to the layer to help prevent overfitting during training.\n",
    "    - Add dropout after dense layers if necessary to further prevent overfitting during training.\n",
    "    - Conclude with a dense layer with 10 neurons (one for each class) using the softmax activation function for multi-class classification.\n",
    "\"\"\"\n",
    "\n",
    "def build_model():\n",
    "    \n",
    "    # Write code here--\n",
    "    \n",
    "    \n",
    "    return # Return the build model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2982fc",
   "metadata": {},
   "source": [
    "# *Compile and Train the Model*\n",
    "\n",
    "Compile and traning the build model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa11fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model by using the \"compile_and_train()\" function. \n",
    "\n",
    "\"\"\"------- Instructions --------\n",
    "    - The function consits of three tasks where one is optional.\n",
    "    - We appriciate if you perform the optional task.\n",
    "    - Task 1 related to use of compile function. It has few hyperparametrs those are important\n",
    "    - to configure the learning process of the model.\n",
    "    - Task 2 related to use of fit function. It has few hyperparametrs those are important to train the model using dataset.\n",
    "    - In the Task optional, \"callbacks[]\" used to perform actions such as saving the model weights,\n",
    "    - logging training metrics, or stopping the training process early if the model is not improving.\n",
    "\"\"\"\n",
    "\n",
    "def compile_and_train(): # Insert parameters name \n",
    "    \n",
    "    \"\"\"------- Optional Task - Declare callbacks.----------\n",
    "    Instruction:\n",
    "        - Uncomment \"callbacks[]\" if it is necessary.\n",
    "        - Use only \"EarlyStopping()\" or \"ReduceLROnPlateau()\" or both functions.\n",
    "        - Write necessary hyperparameters inside the function.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\" ----------- Task 1 - Compile Function. -------------\n",
    "    Instruction:\n",
    "        - Use compile function write all the necessary hyperparameters inside the complie function.\n",
    "        - For example \"model.compile()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"---------- Task 2 - Fit Function.------------\n",
    "    Instruction:\n",
    "        - Use fit function and write all the necessary hyperparameters inside the fit function.\n",
    "        - For example \"model.fit()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "        - Store the results after fitting the model in \"history\".\n",
    "        - Don't forget to split the dataset for validation.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    \n",
    "    return  # Return \"history\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b8454",
   "metadata": {},
   "source": [
    "# *Plotting Training and Validation Figures*\n",
    "\n",
    "Plot the training and validation loss and accuracy figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd9abe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"plot_metrics()\" function help to plot loss and accuracy figure of the training and validation.\n",
    "\n",
    "def plot_metrics(): # Insert parameter name \n",
    "    \n",
    "    # Plot traning and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot traning and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7fbca8",
   "metadata": {},
   "source": [
    "# *Evaluate the Model and Plot the Confusion Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eeaae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"evaluate_and_confusion_matrix()\" function display the evalutaion result after training and testing the model. \n",
    "\n",
    "def evaluate_and_confusion_matrix(): # Insert parameters name \n",
    "    \n",
    "    # Predictions for the training set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "    y_true_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Predictions for the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate and print the training and test accuracy\n",
    "    train_accuracy = accuracy_score(y_true_train, y_train_pred_classes)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Calculate and print the F1 score for the test set\n",
    "    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624cdc",
   "metadata": {},
   "source": [
    "# *Main Section*\n",
    "\n",
    "The main section is responsible for calling all the functions, each of which has specific tasks to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e45d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------------------------------This is the main section------------------------------\n",
    "\n",
    "\"\"\"------------Task 1: Dataset loading------------------------------\n",
    "\n",
    "Instruction:\n",
    "    Call the \"load_data()\" function to load the MNIST dataset. \n",
    "    This function returns two tuples: one for the training data and another for the testing data.\n",
    "    Each tuple contains a set of images and their corresponding labels.\n",
    "    Store the images and labels in the following variables:\n",
    "    x_train: training images\n",
    "    y_train: training labels\n",
    "    x_test: testing images\n",
    "    y_test: testing labels\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"------------- Task 2: First 10 Images Visualization--------------------------\n",
    "Instruction:\n",
    "    Call the \"plot_first_ten_images()\" function to display the first ten images from the dataset.\n",
    "    This function takes two arguments:\n",
    "        - 'images': a collection of image data, usually as an array where each element is an image.\n",
    "        - 'labels': the corresponding labels for each image, indicating the class or category of the image.\n",
    "    The function creates a 1x10 grid of subplots, where each subplot will display one of the first ten images\n",
    "    in 'grayscale' and title it with its corresponding label.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"-----------  Task 3: Prepare Datset-----------------------------------------\n",
    "Instruction:\n",
    "    Call the \"prepare_data()\" function to perform preprocessing on the training and test datasets.\n",
    "    This function will execute feature extraction, normalization, flattening, and one-hot encoding of labels.\n",
    "    The output will be the prepared dataset, ready for training a neural network.\n",
    "    You will receive four variables as a result:\n",
    "        - \"x_train_flat\": Training data features, flattened for the neural network input.\n",
    "        - \"y_train_encoded\": Training data labels, one-hot encoded.\n",
    "        - \"x_test_flat\": Test data features, similarly flattened.\n",
    "        - \"y_test_encoded\": Test data labels, one-hot encoded.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----------- Task 4: Build the model----------------------------------------\n",
    "Instruction:\n",
    "    Call the \"build_model()\" function to initialize your artificial neural network model.\n",
    "    The model returned is ready to be compiled and trained with your dataset.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----------Task 5: Compile and Train-------------------------------------\n",
    "Instruction:\n",
    "    Call the \"compile_and_train()\" function to compile and train your neural network model.\n",
    "    The function requires three arguments:\n",
    "        - 'model': The ANN model you previously built with the \"build_model()\" function.\n",
    "        - 'x_train_flat': The flattened feature data from your training set, prepared for neural network input.\n",
    "        - 'y_train_encoded': The one-hot encoded labels from your training set.\n",
    "    This function will first compile the model with the necessary configurations and then fit the model on the training data.\n",
    "    The output \"history\" object will contain information about the training process, such as loss and accuracy for each epoch.\n",
    "    Execute the following line of code to start the compilation and training process:\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"------------ Task 6: Plotting Training Metrics------------------------------\n",
    "Instruction:\n",
    "    Call the \"plot_metrics()\" function to visualize the training and validation metrics.\n",
    "    Pass the 'history' object, which contains the training history of the model, as an argument to the function.\n",
    "    This function will generate plots for both the loss and accuracy of the model during training.\n",
    "    It helps to assess the model's performance and to identify if the model is overfitting or underfitting.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"---------- Task 7: Model Evaluation and Confusion Matrix Visualization-----\n",
    "Instruction:\n",
    "    Call the \"evaluate_and_confusion_matrix()\" function to evaluate the model's performance on both the training and testing data.\n",
    "    This function will also plot the confusion matrix for the test data, providing insight into the model's classification accuracy across different classes.\n",
    "    The function takes the following parameters:\n",
    "        - 'model': The trained ANN model.\n",
    "        - 'x_train_flat': The flattened training data features.\n",
    "        - 'y_train_encoded': The one-hot encoded training data labels.\n",
    "        - 'x_test_flat': The flattened testing data features.\n",
    "        - 'y_test_encoded': The one-hot encoded testing data labels.\n",
    "    After execution, the function will display the training and test accuracy and plot the confusion matrix.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209b020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
