{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c137da0",
   "metadata": {},
   "source": [
    "# DVA263 - Applied Machine Learning\n",
    "\n",
    "### Exercise\n",
    "\n",
    "This exercise involves the development of an Convolutional Neural Network (CNN) that classifies handwritten digits from the MNIST dataset. The task will require preprocessing the data, constructing the network, and then training the model to recognize digit images.\n",
    "\n",
    "<span style=\"color:red\">Note:</span>\n",
    "Please make sure that the system have following packages installed before doing the exercise.\n",
    "* Numpy\n",
    "* Tensorflow\n",
    "* Scikit-learn\n",
    "* Matplotlib\n",
    "* Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bb9054",
   "metadata": {},
   "source": [
    "# *Libraries*\n",
    "\n",
    "Libraries have already been declared. Please declare any additional libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0a4ca",
   "metadata": {},
   "source": [
    "# *Load the MNIST Dataset*\n",
    "\n",
    "The MNIST dataset consists of 60,000 images for training and 10,000 images for testing, all of which contain handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd951af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for loading the MNIST handwritten dataset.\n",
    "# You do not have to change anything.\n",
    "\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b179abe",
   "metadata": {},
   "source": [
    "# *Plot First Ten Images*\n",
    "\n",
    "Plotting images will help to understand the how each image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for visualize first 10 image.\n",
    "# You do not have to change anything.\n",
    "\n",
    "def plot_first_ten_images(images, labels):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i], cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b00f2",
   "metadata": {},
   "source": [
    "# *Prepare Final Data*\n",
    "\n",
    "Prepare the dataset for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3dd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(): # Insert parameters name \n",
    "    \n",
    "    # Please perform follwoing tasks to prepare final data\n",
    "    \n",
    "    \n",
    "    \"\"\"------------ Task 1 - Normalization -------------\n",
    "    Instruction:\n",
    "        - Normalize the pixel values of the images from the range [0, 255] to [0, 1] for both training and test sets. \n",
    "        - This is done by dividing by the maximum value of a pixel, which is 255.\n",
    "        - Store the normalized data in \"x_train\" and \"x_test\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "\n",
    "\n",
    "    \"\"\"------------- Task 2 - Reshape Images -----------\n",
    "     Instruction:\n",
    "        - Reshape the images to include a channel dimension, going from (28, 28) to (28, 28, 1),\n",
    "        - because the CNN expects three-dimensional inputs (height, width, channels).\n",
    "        - Store the reshaped data again in \"x_train\" and \"x_test\".\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "\n",
    "    \n",
    "    \"\"\"------------- Task 3 - One-Hot Encoding ----------\n",
    "    Instruction:\n",
    "        - Convert the categorical integer labels into a binary matrix representation using one-hot encoding.\n",
    "        - This step is crucial for classification tasks to properly format the labels for the output layer of the network.\n",
    "        - Store the one-hot encoding data in \"y_train\" and \"y_test\".\n",
    "    \"\"\"\n",
    "    # Write code here--\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"--------- Task 4 - After these preprocessing steps, the function will return four variables---------\n",
    "        - \"x_train\": the reshaped training features\n",
    "        - \"y_train\": the one-hot encoded training labels\n",
    "        - \"x_test\": the reshaped testing features\n",
    "        - \"y_test\": the one-hot encoded testing labels\n",
    "    \"\"\"\n",
    "    return  # Insert the name of four variables as instruction to return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c170f",
   "metadata": {},
   "source": [
    "# *Build CNN Model*\n",
    "\n",
    "Build the CNN model using hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6826cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"---- Task - Define your Convolutional Neural Network (CNN) Architecture inside the \"build_cnn_model()\" function----\n",
    "\n",
    "Instruction:\n",
    "    - Use the Sequential model from Keras to stack layers in a linear format.\n",
    "    - Start with convolutional layer where 'input_shape' should be set to (28, 28, 1) to match the shape of the MNIST images.\n",
    "    - It's ideal to start with a kernel filter size of (3, 3) and explore using more filters as needed.\n",
    "    - Use necessary activation function in each layer.\n",
    "    - Use max pooling layers to reduce the spatial dimensions of your output volume after the convolutional layers.\n",
    "    - Use a flatten layer to transform the 2D feature maps into a 1D feature vector before feeding it into the dense layer.\n",
    "    - Continue adding dense layers reducing the number of neurons in each subsequent layer.\n",
    "    - Apply L2 regularization if necessary to the layer to help prevent overfitting during training.\n",
    "    - Add dropout after dense layers if necessary to further prevent overfitting during training.\n",
    "    - Finish with a Dense output layer with 10 units and a 'softmax' activation to handle the multi-class classification, \n",
    "    - where each unit corresponds to one of the ten classes of the MNIST digits (0-9).\n",
    "\"\"\" \n",
    "\n",
    "def build_cnn_model():\n",
    "    \n",
    "    # Write code here----\n",
    "    \n",
    "    return # Return the build model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2982fc",
   "metadata": {},
   "source": [
    "# *Compile and Train the Model*\n",
    "\n",
    "Compile and traning the build model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"------Compile and train the model by using the \"compile_and_train()\" function.------ \n",
    "Instruction:\n",
    "    - The function consits of three tasks where one is optional.\n",
    "    - We appriciate if you perform the optional task.\n",
    "    - Task 1 related to use of compile function. It has few hyperparametrs those are important\n",
    "    - to configure the learning process of the model.\n",
    "    - Task 2 related to use of fit function. It has few hyperparametrs those are important to train the model using dataset.\n",
    "    - In the Task optional, \"callbacks[]\" used to perform actions such as saving the model weights,\n",
    "    - logging training metrics, or stopping the training process early if the model is not improving.\n",
    "\"\"\"\n",
    "\n",
    "def compile_and_train(): # Insert parameters name \n",
    "    \n",
    "    \"\"\"----- Optional Task - Declare callbacks.-----\n",
    "    Instruction:\n",
    "        - Uncomment \"callbacks[]\" if it is necessary.\n",
    "        - Use only \"EarlyStopping()\" or \"ReduceLROnPlateau()\" or both functions.\n",
    "        - Write necessary hyperparameters inside the function.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    # End optional task\n",
    "\n",
    "    \"\"\"----- Task 1 - Compile Function.------\n",
    "    Instruction:\n",
    "        - Use compile function write all the necessary hyperparameters inside the complie function.\n",
    "        - For example \"model.compile()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"----- Task 2 - Fit Function.------\n",
    "    Instruction:\n",
    "        - Use fit function and write all the necessary hyperparameters inside the fit function.\n",
    "        - For example \"model.fit()\" where \"model\" already build using \"build_model()\" fucntion.\n",
    "        - Store the results after fitting the model in \"history\".\n",
    "        - Don't forget to split the dataset for validation.\n",
    "    \"\"\"\n",
    "    # Write code here----\n",
    "    \n",
    "    \n",
    "    return # Return \"history\" variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68b8454",
   "metadata": {},
   "source": [
    "# *Plotting Training and Validation Figures*\n",
    "\n",
    "Plot the training and validation loss and accuracy figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9abe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"plot_metrics()\" function help to plot loss and accuracy figure of the training and validation.\n",
    "\n",
    "def plot_metrics(history): # Insert parameter name \n",
    "    \n",
    "    # Plot traning and validation loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot traning and validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7fbca8",
   "metadata": {},
   "source": [
    "# *Evaluate the Model and Plot the Confusion Matrix*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeaae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"evaluate_and_confusion_matrix()\" function display the evalutaion result after training and testing the model. \n",
    "\n",
    "def evaluate_and_confusion_matrix(model, x_train, y_train, x_test, y_test): # Insert parameters name \n",
    "    \n",
    "    # Predictions for the training set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "    y_true_train = np.argmax(y_train, axis=1)\n",
    "\n",
    "    # Predictions for the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate and print the training and test accuracy\n",
    "    train_accuracy = accuracy_score(y_true_train, y_train_pred_classes)\n",
    "    test_accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "    print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Calculate and print the F1 score for the test set\n",
    "    f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4624cdc",
   "metadata": {},
   "source": [
    "# *Main Section*\n",
    "\n",
    "The main section is responsible for calling all the functions, each of which has specific tasks to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e45d73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --------------------------------------This is the main section------------------------------\n",
    "\n",
    "\"\"\"----- Task 1: Dataset loading------\n",
    "\n",
    "Instruction:\n",
    "    - Call the \"load_data()\" function to load the MNIST dataset. \n",
    "    - This function returns two tuples: one for the training data and another for the testing data.\n",
    "    - Each tuple contains a set of images and their corresponding labels.\n",
    "    - Store the images and labels in the following variables:\n",
    "    - x_train: training images\n",
    "    - y_train: training labels\n",
    "    - x_test: testing images\n",
    "    - y_test: testing labels\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 2: First 10 Images Visualization------\n",
    "Instruction:\n",
    "    - Call the \"plot_first_ten_images()\" function to display the first ten images from the dataset.\n",
    "    - This function takes two arguments:\n",
    "    - 'images': a collection of image data, usually as an array where each element is an image.\n",
    "    - 'labels': the corresponding labels for each image, indicating the class or category of the image.\n",
    "    - The function creates a 1x10 grid of subplots, where each subplot will display one of the first ten images\n",
    "    - in 'grayscale' and title it with its corresponding label.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 3: Prepare Datset--------\n",
    "Instruction:\n",
    "    - Call the \"prepare_data()\" function to perform preprocessing on the training and test datasets.\n",
    "    - This function will execute feature extraction, normalization, flattening, and one-hot encoding of labels.\n",
    "    - The output will be the prepared dataset, ready for training a neural network.\n",
    "    - You will receive four variables as a result:\n",
    "    - \"x_train_flat\": Training data features, flattened for the neural network input.\n",
    "    - \"y_train_encoded\": Training data labels, one-hot encoded.\n",
    "    - \"x_test_flat\": Test data features, similarly flattened.\n",
    "    - \"y_test_encoded\": Test data labels, one-hot encoded.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 4: Build the model------\n",
    "Instruction:\n",
    "    - Call the \"build_model()\" function to initialize your artificial neural network model.\n",
    "    - The model returned is ready to be compiled and trained with your dataset.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 5: Compile and Train------\n",
    "Instruction:\n",
    "    - Call the \"compile_and_train()\" function to compile and train your neural network model.\n",
    "    - The function requires three arguments:\n",
    "    - 'model': The ANN model you previously built with the \"build_model()\" function.\n",
    "    - 'x_train_flat': The flattened feature data from your training set, prepared for neural network input.\n",
    "    - 'y_train_encoded': The one-hot encoded labels from your training set.\n",
    "    - This function will first compile the model with the necessary configurations and then fit the model on the training data.\n",
    "    - The output \"history\" object will contain information about the training process, such as loss and accuracy for each epoch.\n",
    "    - Execute the following line of code to start the compilation and training process:\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 6: Plotting Training Metrics------\n",
    "Instruction:\n",
    "    - Call the \"plot_metrics()\" function to visualize the training and validation metrics.\n",
    "    - Pass the 'history' object, which contains the training history of the model, as an argument to the function.\n",
    "    - This function will generate plots for both the loss and accuracy of the model during training.\n",
    "    - It helps to assess the model's performance and to identify if the model is overfitting or underfitting.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"----- Task 7: Model Evaluation and Confusion Matrix Visualization-----\n",
    "Instruction:\n",
    "    - Call the \"evaluate_and_confusion_matrix()\" function to evaluate the model's performance on both the training and testing data.\n",
    "    - This function will also plot the confusion matrix for the test data, providing insight into the model's classification accuracy across different classes.\n",
    "    - The function takes the following parameters:\n",
    "       - 'model': The trained ANN model.\n",
    "       - 'x_train_flat': The flattened training data features.\n",
    "       - 'y_train_encoded': The one-hot encoded training data labels.\n",
    "       - 'x_test_flat': The flattened testing data features.\n",
    "       - 'y_test_encoded': The one-hot encoded testing data labels.\n",
    "    - After execution, the function will display the training and test accuracy and plot the confusion matrix.\n",
    "\"\"\"\n",
    "# Write code here----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209b020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
